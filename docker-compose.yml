version: "3.3"

services:
  story-generation:
    build:
      context: ./ai/story-generation
      dockerfile: dockerfile
    env_file: ./ai/.env
    ports:
      - "8001:8001"
    restart: always
    networks:
      - ai-network

  child-monitoring:
    build:
      context: ./ai/child-monitoring
      dockerfile: dockerfile
    env_file: ./ai/.env
    ports:
      - "8002:8002"
    restart: always
    networks:
      - ai-network

  libretranslate:
    image: libretranslate/libretranslate:latest
    ports:
      - "8003:8003"             # host:container
    command: >
      --host 0.0.0.0
      --port 8003
      --load-only en,id
      --update-models
    volumes:
      - lt-models:/root/.local/share/argos-translate
    restart: always
    networks:
      - ai-network

  backend:
    build:
      context: ./backend
      dockerfile: dockerfile
    env_file:
      - ./backend/.env
    ports:
      - "8000:8000"
    depends_on:
      - mongo
      - libretranslate
    restart: always
    networks:
      - ai-network

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"
    restart: always
    networks:
      - ai-network

  cloudflared:
    image: cloudflare/cloudflared:latest
    command: tunnel --no-autoupdate run --token eyJhIjoiNDk3NzQyYmMzOGU4ZTEwYzI3YmU3NzNkZjEyZmNkZGIiLCJ0IjoiNDE5Y2MyY2QtMDVkYS00MzQ5LTgzYTMtODVmODJiYTZkNTFlIiwicyI6Ik9USTFZV05oWWpVdE5tWm1OaTAwTUdFMkxXSm1OamN0TmpGaE1qTXpNMkU0TTJZMiJ9
    restart: unless-stopped
    depends_on:
      - backend
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge

volumes:
  lt-models:
